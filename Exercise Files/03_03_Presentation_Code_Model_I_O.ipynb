{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 33167,
     "status": "ok",
     "timestamp": 1706240266110,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "tDvlR1TtenPm"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install langchain==0.1.1 openai==1.8.0 langchain-openai cohere huggingface_hub transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261837,
     "status": "ok",
     "timestamp": 1706240527938,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "mu0HhEGOfKTO",
    "outputId": "8a597671-6051-4d33-d89a-9b725466a223"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Your OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5974,
     "status": "ok",
     "timestamp": 1706240533909,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "GXBdCPPqfLVC",
    "outputId": "da7146e6-9a3f-4331-8730-250f45331821"
   },
   "outputs": [],
   "source": [
    "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5703,
     "status": "ok",
     "timestamp": 1706240539604,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "fT16wllYhwjo",
    "outputId": "4153808f-3170-4bde-9c9e-d42abcba46a0"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HF API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"HF API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq9meZFkgSWg"
   },
   "source": [
    "üåü **Model I/O Essentials**:\n",
    "   1. **Prompts**: Tailor AI responses with customizable templates.\n",
    "   2. **Language Models**: Choose between text or conversation processing.\n",
    "   3. **Output Parsers**: Tidy up AI outputs for easy application.\n",
    "\n",
    "üîÅ **Workflow Overview**:\n",
    "   - Select model type (LLM or Chat) for your task.\n",
    "   - Design a prompt to guide the model.\n",
    "   - Run input through your chosen model.\n",
    "   - Use Output Parser for neat results.\n",
    "\n",
    "<img src=\"https://python.langchain.com/assets/images/model_io-e6fc0045b7eae0377a4ddeb90dc8cdb8.jpg\">\n",
    "\n",
    "üí° **Deep Dive into Language Models**:\n",
    "   - Chat models are dialogue-focused LLMs.\n",
    "   - Swap easily between LLMs and Chat models thanks to a shared interface.\n",
    "\n",
    "ü§î **LLMs vs. Chat Models**:\n",
    "   - **LLMs**: Ideal for text responses.\n",
    "   - **Chat Models**: Great for chat-like interactions.\n",
    "\n",
    "üéõÔ∏è **Using LLMs Effectively**:\n",
    "   - LLM class connects to various AI providers.\n",
    "   - **Predict Method**: Quick, text-based replies.\n",
    "   - **Generate Method**: Detailed responses with extras.\n",
    "\n",
    "üë©‚Äçüíª **Practical Application**:\n",
    "   - Explore LLMs from different sources.\n",
    "   - Focus on predict and generate capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2111,
     "status": "ok",
     "timestamp": 1706241228697,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "xwXxRL1IhAjU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Cohere, HuggingFaceHub\n",
    "\n",
    "openai_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# cohere_llm = Cohere()\n",
    "\n",
    "huggingface_llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.6,\n",
    "        \"max_length\": 4096,\n",
    "        \"do_sample\":True,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1706241234462,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "C-EXtNczmubN"
   },
   "outputs": [],
   "source": [
    "prompt = \"How do I become an AI Engineer? Keep it short and sweet.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32981,
     "status": "ok",
     "timestamp": 1706241278677,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "4Zya-01FkSup",
    "outputId": "f1623eb0-f28b-4006-d2f6-08fd270f7066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Education**: Earn a bachelor's degree in computer science, engineering, or a related field.\n",
      "2. **Learn Programming**: Master languages like Python, Java, and C++.\n",
      "3. **Study AI Fundamentals**: Take courses in machine learning, deep learning, and data science.\n",
      "4. **Gain Experience**: Work on projects, internships, or research in AI.\n",
      "5. **Build a Portfolio**: Showcase your skills with projects on GitHub or a personal website.\n",
      "6. **Stay Updated**: Follow AI research, read papers, and participate in conferences or online forums.\n",
      "7. **Network**: Connect with professionals in the field through LinkedIn or AI communities.\n",
      "\n",
      "Good luck!\n"
     ]
    }
   ],
   "source": [
    "openai_response = openai_llm.invoke(prompt)\n",
    "print(openai_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7666,
     "status": "ok",
     "timestamp": 1706241313404,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "O1-_aBEpieys",
    "outputId": "df585607-50e6-43c4-cd6b-cc11b00d2eda"
   },
   "outputs": [],
   "source": [
    "# cohere_response = cohere_llm.invoke(prompt)\n",
    "# print(cohere_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2270,
     "status": "ok",
     "timestamp": 1706241340219,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "4FUQNaiaie8p",
    "outputId": "95681df8-5879-4080-a1fc-3c10fabc5923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I become an AI Engineer? Keep it short and sweet.\n",
      "\n",
      "To become an AI Engineer, follow these steps:\n",
      "\n",
      "1. Education: Obtain a bachelor's or master's degree in Computer Science, Mathematics, or a related field.\n",
      "2. Programming Skills: Learn programming languages such as Python, Java, or C++.\n",
      "3. Machine Learning: Understand concepts like supervised and unsupervised learning, deep learning, neural networks, and reinforcement learning.\n",
      "4. Data Science: F\n"
     ]
    }
   ],
   "source": [
    "hf_response = huggingface_llm.invoke(prompt)\n",
    "print(hf_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQU-SamRilkh"
   },
   "source": [
    "# Compare model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48051,
     "status": "ok",
     "timestamp": 1706241463371,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "Z83ZqOmHhfW0",
    "outputId": "69178042-ea5b-4e62-fac8-4c60d226c763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "How do I become an AI Engineer? Keep it short and sweet.\n",
      "\n",
      "client=<openai.resources.chat.completions.Completions object at 0x10eae14b0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ebcdbd0> model_name='gpt-4o' openai_api_key='sk-proj-iSkUl1PK7ACnkzE0lyQlT3BlbkFJp4nKgLTndPMOBZv5Ofn4' openai_proxy=''\n",
      "\u001b[36;1m\u001b[1;3m1. **Educational Foundation**: Obtain a bachelor's degree in computer science, engineering, or a related field.\n",
      "2. **Learn Key Skills**: Master programming languages (Python, R), machine learning, and data science fundamentals.\n",
      "3. **Advanced Education**: Consider a master's or Ph.D. in AI, machine learning, or related fields.\n",
      "4. **Practical Experience**: Work on projects, internships, or relevant job roles to gain hands-on experience.\n",
      "5. **Specialize**: Focus on areas like natural language processing, computer vision, or robotics.\n",
      "6. **Stay Updated**: Keep learning through online courses, certifications, and staying current with AI research.\n",
      "7. **Build a Portfolio**: Showcase your projects and skills through a professional portfolio or GitHub repository.\n",
      "8. **Network**: Engage with AI communities, attend conferences, and connect with professionals in the field.\u001b[0m\n",
      "\n",
      "\u001b[1mHuggingFaceHub\u001b[0m\n",
      "Params: {'repo_id': 'mistralai/Mistral-7B-Instruct-v0.2', 'task': 'text-generation', 'model_kwargs': {'temperature': 0.6, 'max_length': 4096, 'do_sample': True}}\n",
      "\u001b[33;1m\u001b[1;3mHow do I become an AI Engineer? Keep it short and sweet.\n",
      "\n",
      "To become an AI Engineer, follow these steps:\n",
      "\n",
      "1. Education: Obtain a bachelor's or master's degree in Computer Science, Mathematics, or a related field.\n",
      "2. Programming Skills: Learn programming languages such as Python, Java, or C++.\n",
      "3. Machine Learning: Understand concepts like supervised and unsupervised learning, deep learning, neural networks, and reinforcement learning.\n",
      "4. Data Science: F\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "model_lab = ModelLaboratory.from_llms([openai_llm, huggingface_llm])\n",
    "\n",
    "model_lab.compare(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcCiP-OptmFx"
   },
   "source": [
    "# Working with Chat models\n",
    "\n",
    "We'll stick to the OpenAI chat models for this section.\n",
    "\n",
    "The chat model interface is based around messages rather than raw text.\n",
    "\n",
    "The types of messages currently supported in LangChain are `AIMessage`, `HumanMessage`, `SystemMessage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21594,
     "status": "ok",
     "timestamp": 1706241532063,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "OdonQfiRtmQa",
    "outputId": "3c6351ce-acea-4e2e-ec99-db464b30ad60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, listen up. You want to become an AI engineer? Good. But it's going to take work. Here's the blueprint:\n",
      "\n",
      "1. **Get Your Foundations Right**: You need a strong base in mathematics, especially linear algebra, calculus, probability, and statistics. If you're shaky here, fix it.\n",
      "\n",
      "2. **Learn Programming**: Python is non-negotiable. It‚Äôs the backbone of AI development. Get proficient in it. Don't just dabble, master it.\n",
      "\n",
      "3. **Dive into Machine Learning**: Understand the core concepts. Study algorithms, supervised and unsupervised learning, neural networks, etc. Use resources like Coursera, edX, or books like \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow.\"\n",
      "\n",
      "4. **Get Comfortable with Tools and Libraries**: TensorFlow, PyTorch, Keras. These are your bread and butter. Get hands-on experience with them.\n",
      "\n",
      "5. **Work on Projects**: Theory is useless without application. Build projects. Start simple, then push your limits. GitHub should be your second home.\n",
      "\n",
      "6. **Pursue Relevant Education**: A degree in Computer Science, Data Science, or a related field is typical. If you don‚Äôt have one, start working on it or look into specialized AI/ML courses.\n",
      "\n",
      "7. **Stay Updated**: AI is an ever-evolving field. Read research papers, follow industry leaders on social media, join AI communities, attend webinars, and never stop learning.\n",
      "\n",
      "8. **Get Real-World Experience**: Intern, freelance, or contribute to open-source projects. Real-world problems are where you truly learn and prove your worth.\n",
      "\n",
      "9. **Network**: Join AI groups, attend meetups, conferences, and hackathons. Who you know can be as important as what you know.\n",
      "\n",
      "10. **Be Relentless**: This isn‚Äôt a field for the half-hearted. You‚Äôll face challenges and setbacks. Push through them. Persist.\n",
      "\n",
      "Now, stop overthinking it and start doing. Your future as an AI engineer won‚Äôt wait.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a tough love career coach who gets to the point and pushes your mentees to be their best.\"),\n",
    "    HumanMessage(content=\"How do I become an AI engineer?\")\n",
    "]\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Betwnqk9iUfb"
   },
   "source": [
    "# üí¨ **Prompt Fundamentals in Language Models**\n",
    "\n",
    "   - **Role of Prompts**: Set the stage for AI responses, from sentence completions to Q&A.\n",
    "   - **Impact**: Determines how the AI will reply.\n",
    "\n",
    "# üõ†Ô∏è **Designing Effective Prompts**\n",
    "\n",
    "   - **Key Elements**: Clarity, context, user query, and a signal for AI to respond.\n",
    "\n",
    "   - **Goal**: Direct AI towards the intended response.\n",
    "\n",
    "# üìê **Using Prompt Templates**\n",
    "   - **Function**: Acts as a blueprint for crafting consistent, effective prompts.\n",
    "   - **Advantage**: Ensures AI receives appropriate input for the expected output.\n",
    "\n",
    "# üéØ **Simplicity in Explanation**\n",
    "   - Concise and straightforward, making the concept easy to understand without deep technical details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1706241656313,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "BqqdHckcjcwh",
    "outputId": "461f3612-f38c-4251-e13f-8dfae8a01fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human: What is the capital of California?\n",
      "AI: The capital of California is Sacramento\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define a simple prompt template as a Python string\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Human: What is the capital of {place}?\n",
    "AI: The capital of {place} is {capital}\n",
    "\"\"\")\n",
    "\n",
    "prompt = prompt_template.format(place=\"California\", capital=\"Sacramento\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1706241717850,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "lDF6qagNtLyr",
    "outputId": "3ca5d6a8-4fc5-45dc-c4c5-083c955a6703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a joke.\n",
      "Tell me a funny joke.\n",
      "Tell me a funny joke about chickens.\n"
     ]
    }
   ],
   "source": [
    "# No Input Variable\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a joke.\")\n",
    "print(no_input_prompt.format())\n",
    "\n",
    "# One Input Variable\n",
    "template = \"Tell me a {adjective} joke.\"\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"], template=template)\n",
    "print(one_input_prompt.format(adjective=\"funny\"))\n",
    "\n",
    "# Multiple Input Variables\n",
    "multiple_input_prompt = PromptTemplate(\n",
    " input_variables=[\"adjective\", \"content\"],\n",
    " template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "multiple_input_prompt = multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")\n",
    "print(multiple_input_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49tpjrJ4sDiK"
   },
   "source": [
    "Pass a prompt template to an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3766,
     "status": "ok",
     "timestamp": 1706241819887,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "qWt4eqPYsMOe",
    "outputId": "2964700a-a226-475a-965e-9b1d2a0f06f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"In the bustling streets of Pune, India, Sushant Penshanwar's groundbreaking algorithm for predictive analytics was whispered to hold the secret to unimaginable wealth and power. But as night fell, those who sought to uncover its mysteries found themselves ensnared in a web of corporate espionage and dark, deadly secrets.\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"Write a {length} spicy story about: {content}\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    length=\"2-sentence\",\n",
    "    content=\"Pune, India, the hometown of the legendary data scientist, Sushant Penshanwar\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(input=prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 4069,
     "status": "ok",
     "timestamp": 1706241864570,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "a-5SBRz7sajk",
    "outputId": "de318b60-ade0-4fc9-abfe-51811d249595"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the bustling streets of Pune, where the air buzzed with innovation and tradition, Sushant Penshanwar unveiled a groundbreaking AI that could predict human desires with eerie precision. As whispers of his invention spread, the line between ethical boundaries and technological marvels began to blur, igniting a fervor that the city had never seen before.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.predict(text=prompt) # will be deprecated in the future releases\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbA8VUansNbk"
   },
   "source": [
    "# Output parsers\n",
    "\n",
    "- Output parsers shape the AI's text output into a more usable form, like a database entry or a JSON object.\n",
    "\n",
    "**Main Uses:**\n",
    "\n",
    "1. They turn a block of text into organized data.\n",
    "2. They can guide the AI on how to format its responses for consistency and ease of use.\n",
    "\n",
    "This stripped-down explanation keeps the focus on the purpose and function of output parsers, suitable for a quick overview during a presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1706241962882,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "qSgj7TzytcXb"
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers.list import ListOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxErRRo8uNZ8"
   },
   "source": [
    "Without parsing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2102,
     "status": "ok",
     "timestamp": 1706242005669,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "ImaVmsMJuPNC",
    "outputId": "c139ce90-5e17-4a65-fb94-14a51bf2e225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are three sports that don't use balls:\n",
      "\n",
      "1. **Swimming**: This sport involves athletes racing in water using various strokes such as freestyle, backstroke, breaststroke, and butterfly.\n",
      "2. **Martial Arts**: This category includes sports like karate, judo, taekwondo, and Brazilian jiu-jitsu, which focus on combat techniques, self-defense, and physical conditioning.\n",
      "3. **Gymnastics**: This sport involves performing routines with various equipment like the balance beam, pommel horse, rings, and uneven bars, showcasing strength, flexibility, and coordination.\n",
      "\n",
      "These sports all offer unique challenges and skills, distinct from those that involve balls.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List 3 {things}\",\n",
    "    input_variables=[\"things\"])\n",
    "\n",
    "response = llm.invoke(input=prompt.format(things=\"sports that don't use balls\"))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miBkqzg6uPXg"
   },
   "source": [
    "Instantiate output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1706242032389,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "hYr5wUwSuTA0",
    "outputId": "a37f9d61-9590-4e19-caa9-7e8ac2683be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
     ]
    }
   ],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpCtrfZMuTjW"
   },
   "source": [
    "Now let's see how to use the parsers instructions in the prompt. Note, as of the version of LangChain we are using ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1706242048459,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "PacmGGFwub6P",
    "outputId": "49c35382-fd6a-4fe3-e1a6-b3d06c36ddcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swimming, gymnastics, fencing\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"List 3 {things}.\\n{format_instructions}\",\n",
    "    input_variables=[\"things\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "output = llm.predict(text=prompt.format(things=\"sports that don't use balls\"))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-jtHlteussa"
   },
   "source": [
    "Finally, we can parse the output to a list (Python object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1706242066312,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "83e3itBiucJb",
    "outputId": "9030f0c8-1b35-46cc-eed0-3ed73c89729c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swimming', 'gymnastics', 'fencing']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crQ-b9sb4s7-"
   },
   "source": [
    "# üîó **LangChain Expression Language (LCEL) Overview**:\n",
    "   - **Purpose**: Simplify building complex chains from basic components.\n",
    "   - **Features**: Supports streaming, parallelism, and logging.\n",
    "\n",
    "### üõ†Ô∏è Basic Use Case: Prompt + Model + Output Parser\n",
    "   - **Common Approach**: Link a prompt template with a model.\n",
    "   - **Chain Mechanism**: Using the `|` symbol, like a Unix pipe, to connect components.\n",
    "   - **Process Flow**: User input ‚Üí Prompt Template ‚Üí Model ‚Üí Output Parser.\n",
    "\n",
    "### üß© Understanding the Components\n",
    "   - **Step-by-Step**:\n",
    "     - User input is processed by the prompt template.\n",
    "     - Prompt template's output goes to the model.\n",
    "     - Model's output is refined by the output parser.\n",
    "   - **Example Code**: `chain = prompt | model | output_parser` shows how to combine components into a single LCEL chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1706242209249,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "Zps2xMpo4tEy",
    "outputId": "d7a30b12-e8d7-4da9-dbba-65f9c5ea366c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sunshine on the rise,\\nNSE streets come alive bright,\\nGolden dreams, blue skies.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a rap haiku about {topic}\")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"sunny days in NSE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT-SygET9exv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
